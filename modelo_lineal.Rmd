---
title: "Modelo Lineal Simple"
subtitle: "Aplicación a la Esperanza de Vida y Tasa de Analfabetismo"
author: Bladimir Morales Torrez
date: "09 de Agosto 2020"
output: 
  html_notebook:
    number_sections: true
    toc: true
    toc_float: true
    theme: flatly
    fig_retina: 2
    df_print: paged
    code_folding: hide
---

```{r setup,include=FALSE}
knitr::opts_chunk$set(echo=TRUE)
library(dplyr)
library(reshape2)
library(readxl)
library(ggplot2)
library(highcharter)
```

Las librerias a utilizar en R.

```{r librerias,eval=FALSE}
library(dplyr)
library(reshape2)
library(readxl)
library(ggplot2)
library(highcharter)
#rm(list=ls())
```

En este documento se pretende calcular un modelo de regresión lineal simple para dos variables cuantitativas:

* **Esperanza de Vida**: variable respuesta, dependiente, endógena o explicada $Y$ .

* **Tasa de analfabetismo**: variable predictora, independiente, exógena o explicativa $X$.

# Datos

Los datos utilizados son del [Banco Mundial](https://datos.bancomundial.org/):

* [Esperanza de vida](https://datos.bancomundial.org/indicator/SP.DYN.LE00.IN) para el año 2018.

```{r datos_esp_vida}
esp_vida=read_xls("C:/Users/Bladimir/Documents/Proyectos/Modelo_lineal/BD/esperanzavida.xls") %>% 
  select(pais,cod_pais,esp_vida="2018") %>% 
  dplyr::filter(!is.na(esp_vida))
esp_vida[2:3]
```


* [Tasa de Analfabetismo](https://datos.bancomundial.org/indicator/SE.ADT.LITR.ZS) para el año 2018.


```{r datos_tasa_analfab}
tasa_analfab=read_xls("C:/Users/Bladimir/Documents/Proyectos/Modelo_lineal/BD/analfabetismo.xls") %>% 
  select(pais,cod_pais,tasa_analfab="2018") %>% 
  dplyr::filter(!is.na(tasa_analfab))
tasa_analfab[2:3]
```


Hacemos una union de las dos bases de datos.

```{r bd}
bd=inner_join(tasa_analfab,esp_vida)
bd[2:3]
```

# Análisis de variables

Antes de utilizar un modelo lineal se debe evaluar si existe algún tipo de relación entre las variables es por eso que se utilizará el coeficiente de correlación de Pearson y una observación gráfica de los datos.

## Coeficiente de Correlación de Pearson

El coeficiente de correlación de Pearson tiene la siguiente ecuación:

$$r=\frac{Cov(X,Y)}{\sigma_x  \sigma_y} $$

El valor de $r$ solo puede estar entre el intervalo de $(-1,\;1)$ debido al signo de la covarianza y para calificar la correlación de dos variables cuantitativas se utiliza la siguiente escala en valor absoluto de $|r|$:

**Escala de Correlación de Pearson**

| **$|r|$**    | **Escala** |
|:-------------|:-----------|
|0.00 - 0.30   | Baja       |
|0.30 - 0.60   | Regular    |
|0.60 - 0.90   | Alta       |
|0.90 - 0.95   | Significativamente alta|
|0.95 - 1.00   | Funcional  |

Ahora se analizará la correlación entre las variables tasa de analfabetismo $Y$ y la esperanza de vida $X$.


```{r correlacion}
cor_1=cor.test(bd$esp_vida,bd$tasa_analfab)
cor_1
```

Se observa que existe un alto grado de correlación positiva de Pearson 

$$r= `r cor_1$estimate`$$

## Dispersograma

El diagrama de dispersión o dispersograma es el gráfico en un plano cartesiano donde el eje $X$ representa a la tasa deanalfabetismo y el eje $Y$ la esperanza de vida.

```{r dipersograma,include=F}
h=hchart(bd,type="scatter",hcaes(x=tasa_analfab,y=esp_vida,group=pais)) %>% 
  hc_legend() %>% 
  hc_title(text="Dispersograma del Analfabetismo y Esperanza de Vida") %>% 
  hc_subtitle(text="Países del Mundo 2018") %>% 
  hc_xAxis(title=list(text="Analfabetismo")) %>% 
  hc_yAxis(title=list(text="Esperanza de vida"))
```

```{r dispersograma_t}
h
```

Se observa que efectivamente existe una correlación positiva entre las variables vale decir que mientras una crece la otra también.

# Modelo de Regresión Lineal Simple

Para el modelo de regresión lineal simple se tendrá solamente dos variables $y_i$ (dependendiente) y $x_i$ (independiente), esta representado por:

$$y_i=\beta_0+\beta_1 x_i+\epsilon_i$$

Donde:

- $y_i$ variable dependiente, endógena, respuesta o explicada.
- $x_i$ variable independiente, exógena, predictora o explicativa.
- $\beta_0$ coeficiente intercepto de la línea con el eje $y$.
- $\beta_1$ coeficiente pendiente de la línea de regresión.
- $\epsilon_i$ errores aleatorios.

Si desarrollamos el modelo para cada observación se tiene las siguientes ecuaciones:

$$\begin{aligned}
y_1&=\beta_0+\beta_1x_1+\epsilon_1\\
y_2&=\beta_0+\beta_1x_1+\epsilon_2\\
\vdots &\hspace{1.5cm}\vdots\hspace{1.5cm}\vdots \\
y_n&=\beta_0+\beta_1x_1+\epsilon_n\\
\end{aligned}
$$

El sistema de ecuaciones matricialmente:

\begin{equation}
\left[\begin{array}{c}
y_1 \\ 
y_2 \\ 
\vdots \\
y_n
\end{array}\right]
=
\left[\begin{array}{cc}
1 & x_1\\
1 & x_2\\
\vdots & \vdots\\
1 & x_n\\
\end{array}\right]

\left[\begin{array}{c}
\beta_0\\
\beta_1
\end{array}\right]
+
\left[\begin{array}{c}
\epsilon_1\\
\epsilon_2\\
\vdots\\
\epsilon_n\\
\end{array}\right]
\end{equation}

Entonces el modelo de regresión lineal simple de manera matricial es:

$$Y=X\beta+\epsilon$$

Supuestos:

La parte aleatoria del modelo vale decir $\epsilon$ se dice que tiene una distribución Normal independiente e identicamente distribuida ($iid$).

$$\epsilon_i \sim iid \; N(0\;,\sigma^2) $$

Entonces si se evalúa la variables respuesta y en primera instancia hallamos la esperanza de $y_i$:

$$
\begin{aligned}
E(y_i|x_i)&=E(\beta_0+\beta_1 x_i+\epsilon_i)\\
          &=E(\beta_0)+E(\beta_1 x_i)+ E(\epsilon_i)\hspace{1cm} ;\beta_0,\beta_1,x_i=cttes. \\
          &=\beta_0+\beta_1x_i+0\\
          &=\beta_0+\beta_1x_i
\end{aligned}
$$

Luego la varianza:

$$
\begin{aligned}
Var(y_i|x_i)&=Var(\beta_0+\beta_1 x_i+\epsilon_i)\hspace{1cm} ;\beta_0,\beta_1,x_i=cttes. \\ 
            &=Var(\epsilon_i)\\
            &=\sigma^2
\end{aligned}
$$

Por lo tanto:

$$y_i|x_i\sim N(\beta_0+\beta_1x_i\; ; \; \sigma^2)$$

Continuando con los datos del banco mundial en  el análisis de variables se concluyó que las dos variables tienen correlación positiva, entonces se estima el modelo de regresión lineal simple.

$$Y=X\beta+\epsilon$$


## Coeficientes del modelo

Los coeficientes del modelo de regresión lineal simple vale decir $\beta_0$ y $\beta_1$ deben ser estimados, es por eso que se utiliza la estimación por mínimos cuadrados ordinarios (MCO).

Se parte del modelo de regresión lineal.

$$y_i=\beta_0+\beta_1 x_i+ \epsilon_i$$

Donde igualamos la suma de la parte aleatoria al cuadrado del modelo a una función $Q$ que minimice y depende de $\beta_0$ y $\beta_1$:

$$\begin{aligned}
Q(\beta_0,\beta_1)&=\sum_{i=1}^n \epsilon_i^2\\
                  &=\sum_{i=1}^n (y_i-\beta_0-\beta_1 x_i)^2\\
\end{aligned}
$$

Ahora derivamos $Q$ con respecto a $\beta_0$ y $\beta_1$

$$\begin{aligned}
\frac{\partial Q}{\partial\beta_0}&=\sum_{i=1}^n 2(y_i-\beta_0-\beta_1 x_i)(-1)\\
\frac{\partial Q}{\partial\beta_1}&=\sum_{i=1}^n 2(y_i-\beta_0-\beta_1 x_i)(-x_i)\\
\end{aligned}
$$

Igualamos a cero para minimizar

$$\begin{aligned}
\frac{\partial Q}{\partial\beta_0}&=0\\
\frac{\partial Q}{\partial\beta_1}&=0\\
\end{aligned}
$$

Entonces:

$$
\begin{aligned}
\sum_{i=1}^n 2(y_i-\hat{\beta_0}-\hat{\beta_1} x_i)(-1)&=0\\
\sum_{i=1}^n 2(y_i-\hat{\beta_0}-\hat{\beta_1} x_i)(-x_i)&=0\\
\end{aligned}
$$

Luego el se multiplica las dos ecuaciones por $(\frac{1}{2})$:

$$
\begin{aligned}
-\sum_{i=1}^n y_i + n\hat{\beta_0} + \hat{\beta_1} \sum_{i=1}^nx_i=0\\
-\sum_{i=1}^n x_i y_i + \hat{\beta_0} \sum_{i=1}^n x_i + \hat{\beta_1} \sum_{i=1}^n x_i^2=0\\
\end{aligned}
$$

Primero despejamos $\beta_0$ de la primera ecuación:

$$
\begin{aligned}
n\hat{\beta_0} &=\sum_{i=1}^n y_i - \hat{\beta_1} \sum_{i=1}^n x_i\\
\hat{\beta_0} &=\sum_{i=1}^n \frac{y_i}{n} - \hat{\beta_1} \sum_{i=1}^n \frac{x_i}{n}\\
\hat{\beta_0} &=\overline{y} - \hat{\beta_1} \overline{x}\\
\end{aligned}
$$

Reemplazamos el estimador $\hat{\beta_0}$ en la segunda ecuación de $\hat{\beta_1}$

$$
\begin{aligned}
\hat{\beta_1} \sum_{i=1}^n x_i^2&=\sum_{i=1}^n x_i y_i - \hat{\beta_0} \sum_{i=1}^n x_i \\
\hat{\beta_1} \sum_{i=1}^n x_i^2&=\sum_{i=1}^n x_i y_i - (\overline{y} - \hat{\beta_1} \overline{x}) \sum_{i=1}^n x_i \\
\hat{\beta_1} \sum_{i=1}^n x_i^2&=\sum_{i=1}^n x_i y_i - \overline{y} \sum_{i=1}^n x_i + \hat{\beta_1} \overline{x} \sum_{i=1}^n x_i \\
\hat{\beta_1} \sum_{i=1}^n x_i^2 -  \hat{\beta_1} \overline{x} \sum_{i=1}^n x_i&=\sum_{i=1}^n x_i y_i - \overline{y} \sum_{i=1}^n x_i  \\
\hat{\beta_1}(\sum_{i=1}^n x_i^2 -  \overline{x} \sum_{i=1}^n x_i)&=\sum_{i=1}^n x_i y_i - \overline{y} \sum_{i=1}^n x_i  \hspace{0.5cm};(\frac{1}{n}) \\
\hat{\beta_1}(\frac{\sum_{i=1}^n x_i^2}{n} -  \overline{x}^2)&=\frac{\sum_{i=1}^n x_i y_i}{n} - \overline{y} \overline{x}\\
\hat{\beta_1}(\sigma_x^2) &= cov(x,y)\\
\hat{\beta_1} &= \frac{cov(x,y)}{\sigma_x^2}\\
\end{aligned}
$$

Para los datos del Banco Mundial los siguientes coeficientes del modelo lineal son:

```{r modelo_lin}
mod_lin=lm(esp_vida ~ tasa_analfab,data=bd)
summary(mod_lin)
```

El modelo de regresión lineal será:

$$
\text{Esp_vida}_i= `r mod$coefficients[1]` + `r mod$coefficients[2]`* \text{Tasa_analfabetismo}_i
$$

Interpretación:

-$\beta_0$= `r mod$coefficients[1]` es el valor promedio de la variable respuesta $Y$ cuando $X$ es cero, esto si se tiene certeza de que la variable predictora $X$ es diferente de $0$ ya que la interpretación no tendria sentido.

-$\beta_1$= `r mod$coefficients[2]` indica el cambio promedio de la variable respuesta $Y$ cuando $X$ se incrementa en una unidad.

## Descomposición de la varianza total del modelo lineal

Para la regresión lineal se tiene la descomposición de la varianza de la variable dependiente $Y$:

$$
\begin{aligned}
Var. \;total \;Y &= Var.\; de\; la\; regresión + Var.\; del\; error\\
Var(Y) &= Var(\beta_0+\beta_1 X_i)+ Var(\epsilon_i)\\
\end{aligned}
$$

Primero se parte de la Varianza de $Y$:

$$Var(Y)=\sum_{i=1}^n \frac{1}{n}(y_i-\overline y)^2$$

Entonces si multiplicamos por $(n)$ quedará a lo que se denomina suma de cuadrados total ($SCT$).

$$SCT=\sum_{i=1}^n (y_i-\overline y)^2$$
Ahora se descompone la $SCT$ adicionando y restando $\hat{y_i}$

$$
\begin{aligned}
\sum_{i=1}^n (y_i-\overline y)^2&=\sum_{i=1}^n (y_i-\hat y_i+\hat y_i-\overline y)^2\\
\sum_{i=1}^n (y_i-\overline y)^2&=\sum_{i=1}^n (\hat y_i-\overline y)^2+ \sum_{i=1}^n(y_i-\hat y_i)^2\\
SCT&=SCReg+SCRes\\
\end{aligned}
$$

Si todas las dividimos por $\sigma^2$ tendrán distribución $\chi^2$.

## Análisis de Varianza (ANOVA)

Se desea saber si la variable explicativa o independiente $X$ influye significativamente sobre la variable $Y$. Para esto se tiene el siguiente contraste de hipótesis.

$$
\begin{aligned}
H_0:\; \beta_0 &=0\;\;(X \text{ no influye})\\
H_1:\; \beta_0 &\neq 0 \;\;(X \text{ influye})
\end{aligned}
$$

La ANOVA queda:

Fuente Variación | Grados de lib. | Sum. Cuadrados | Cuadrados Medios | F |
-----------------|----------------|----------------|------------------|---|
Deb. a la Regresión | 1           | SCReg          | CMReg=$\frac{SCReg}{1}$  | $\frac{CMReg}{CMRes}$
Deb. al error       | n-2         | SCRes          | CMRes=$\frac{SCRes}{n-2}$|
Total               | n-1         | SCT            |

Se debe cumplir el siguiente estadístico:

$$CMReg=\frac{SCReg}{g.l.}=\frac{SCReg}{1}\\
CMRes=\frac{SCRes}{g.l.}=\frac{SCReg}{n-2}
$$

La desición de aceptar o rechazar $H_0$ se va a tomar en base al estadístico que se obtiene a partir de análisis de varianza, que tiene una distribución $F$ con $(1;n-2)$ grados de libertad bajo $H_0$ por lo tanto la regla de decisión es la siguiente, se rechaza $H_0$ al nivel de significancia $\alpha$ cuando:

$$
F_c=\frac{CMReg}{CMRes}>F
$$
O también se rechaza $H_0$ si:

$$
p-valor<0.05
$$


```{r prueba_hipotesis_b1}
#Prueba de hipótesis de coeficientes
anova(mod_lin)
```

En el estimador de $\beta_1$ se ve que su $p-valor \;<\;0.05$ por lo tanto se rechaza $H_0:\; \beta_1=0$. 


## Pruebas de Inferencia para los parámetos del modelo de regresión

La prueba de hipótesis para los estimadores de $\hat\beta_0$ y $\hat\beta_1$ es una estadística $t-student$.

$$t_c=\frac{\hat\beta_i}{\sqrt{Var(\hat\beta_i)}}$$

Rechazamos $H_0: \;\beta_i=0$ si la distribución cumple:

$$|t_c|>t_{(1-\frac{\alpha}{2};n-2)}$$

O en su defecto si:
$$p-valor\;<\;0.05$$

```{r hipotesis_b_i}
summary(mod_lin)
```

* Para $\hat\beta_0$ su $p-valor<0.05$ por lo tanto se rechaza $H_0: \beta_0=0$ lo cual muestra que el intercepto de la recta es significativo con lo que el modelo si tiene sentido.

* Para $\hat\beta_1$ su $p-valor<0.05$ por lo tanto se rechaza $H_0: \beta_1=0$ lo cual muestra que la pendiente de la recta es significativa entonces existe una relación lineal entre la variable predictora $X$ y la variable respuesta $Y$.

## Intervalo de confianza para los parámetros del modelo de regresión

El intervalo de confianza es para la pendiente $\beta_1$ es:

$$
\hat{\beta_1}\pm t_{(1-\frac{\alpha}{2};n-2)} \frac{S}{\sqrt{n\sigma^2}}
$$
```{r ic_parametros}
confint(mod_lin,level=0.95)
```

## El coeficiente de Determinación 

Es una medida de bondad de ajuste que es igual al cuadrado del coeficiente de correlación de Pearson $r^2=R^2$


$$r^2=\left(\frac{Cov(X,Y)}{\sigma_x  \sigma_y}\right)^2 $$

O también es equivalente:

$$R^2=\frac{SCReg}{SCT}=1-\frac{SCRes}{SCT}=r_{xy}^2$$

Como $-1<r<1$ entonces $0<R^2<1$

$R^2$ es interpretado como la proporción de variabilidad de la variable respuesta $Y$, que es explicada por su relación lineal con $X$


```{r}
r=summary(mod_lin)
r
```

Para los datos el $R^2=$ `r r$r.squared` lo cual muestra que la esperanza de vida es explicada en un `r r$r.squared*100`$\%$ en relación lineal con la tasa de analfabetismo.

## Coeficiente de Determinación Ajustado

El coeficiente de determinación ajustado $R_a^2$ se utiliza cuando existe mas de una covariables en el modelo vale decir mas de una $X$ y sirve para comparar modelos alternativos con diferentes covariables.

Es determinado de la siguiente forma:

$$
\begin{aligned}
R_a^2&=1-\frac{\frac{SCReg}{n-p-1}}{\frac{SCT}{n-1}}\\
R_a^2&=1-(\frac{n-1}{n-p-1})(1-R^2)
\end{aligned}
$$

Para los datos como solo se tiene una variable no se utiliza el $R_a^2$

## Intervalo de confianza para el valor medio de las predicciones de Y

El intervalo de confianza para el valor medio de todos los predictores de $Y$ dado que $X=x_0$ o escrito de manera formal $E(Y|X=x_0)$ es:

$$\hat{y}\pm t_{(1-\frac{\alpha}{2};n-2)}S\sqrt{\frac{1}{n}+\frac{(x_0-\overline{x})^2}{n\sigma^2}} $$

Si se quiere tener en particular una tasa de analfabetismo $x_0=85$ se puede estimar el intervalo de confianza del $95\%$ para la esperanza de vida media.

```{r int_mediay}
x0=data.frame(tasa_analfab=85)
predict(mod_lin,newdata = x0,interval = "confidence")
```


## Intervalo de confianza para un valor individual de las predicciones de Y

El intervalo de confianza para un valor individual de $Y$ dado que $X=x_0$ o escrito de manera formal $E(Y|X=x_0)$ es:

$$\hat{y_0}\pm t_{(1-\frac{\alpha}{2};n-2)}S\sqrt{1+\frac{1}{n}+\frac{(x_0-\overline{x})^2}{n\sigma^2}} $$

Si queremos tener en particular una tasa de analfabetismo $x_0=85$ se puede estimar el intervalo de confianza del $95\%$ para el valor predicho de la esperanza de vida $\hat{y_0}$.

```{r int_y}
predict(mod_lin,newdata = x0,interval = "prediction")
```


## Gráfico de intervalo de confianza


```{r graf_int}
pred_media=predict(mod_lin,interval="confidence")
pred_individual=predict(mod_lin,interval = "prediction")
bd_pred=cbind(bd,pred_individual)

ggplot(bd_pred,aes(tasa_analfab,esp_vida))+
  geom_point()+
  geom_line(aes(y=lwr),color="red",linetype="dashed")+
  geom_line(aes(y=upr),color="red",linetype="dashed")+
  geom_smooth(method=lm,se=T)+
  labs(title="Modelo de Regresión Lineal",
       caption = "Datos Banco Mundial 2018",
       y="Esperanza de vida",
       x="Tasa de analfabetismo")
```

El intervalo de confianza para los valores individuales de las predicciones de $Y$ que se representa con la interlineada color rojo son necesariamente mas amplios que el intervalo para la media de las prediciones de $Y$ que esta representado como la parte sombreada al rededor de la recta de regresión.

# Análisis de residuos

Los residuos del modelo de regresión están representados:

$$e_i=y_i-\hat y_i$$

Se puede considerar al residual como la estimación de los errores aleatorios $\epsilon_i$.

```{r residuos}
bd_pred$residuos=residuals(mod_lin)
bd_pred$res_estand=rstandard(mod_lin)

ggplot(bd_pred,aes(tasa_analfab,esp_vida))+
  geom_smooth(method = lm,se=F)+
  geom_segment(aes(xend=tasa_analfab,yend=fit),alpha=.4)+
  labs(title="Residuos respecto al modelo lineal",
       y="Esperanza de vida",
       x="Tasa de analfabetismo")
```

En el análisis de los residuos se puede probar la:

* Normalidad de los errores.

* Valores anormales en la distribución de los errores.

* Varianza constante (propiedad de homocedasticidad).

* Independencia de los errores


## Normalidad de los residuos

Se estandariza los residuos:

$$e_{es}=\frac{e_i}{\hat\sigma_\epsilon^2\sqrt{(1-\frac{1}{n}-\frac{(x_0-\overline{x})^2}{n\sigma_x^2})}}$$
### QQ-Plot de Residuos Estandarizados

El gráfico permite observar la normalidad de los errores estandarizados del modelo lineal simple.

```{r qqplot}
bd_pred$res_estand=rstandard(mod_lin)

ggplot(bd_pred)+
  stat_qq(aes(sample=res_estand))+
  geom_abline(color="blue")+
  labs(title="Normal Q-Q Plot",
       y="Residuos Estandarizados",
       x="Teóricos")
```

Si los puntos estan cerca de una linea recta se concluye que hay normalidad.

### Histograma de residuos estandarizados

```{r histograma_res}
ggplot(bd_pred,aes(x=res_estand))+
  geom_histogram()+
  labs(title="Histograma de Residuos Estandarizados",
       x="Residuos estandarizados")
```

Si el histograma es simétrico con un pico en el centro se concluye que hay normalidad en este caso si hay normalidad pero existen algunos puntos atípicos.

### Box plot de residuos estandarizados

```{r boxplot_res}
ggplot(bd_pred,aes(y=res_estand))+
  geom_boxplot()+
  labs(title="Boxplot de Residuos Estandarizados",
       y="Residuos estandarizados")
```

Efectivamente la mediana se encuentra entre el valor $0$ con poca variabilidad mostrando normalidad, pero también se observa un dato atípico.

## Varianza Constante

Se quiere detectar en este análisis si la varianza es constante con respecto a la variable respuesta.

### Gráfico de predichos vs residuales estandarizados

```{r pred_res_estand}
ggplot(bd_pred,aes(fit,res_estand))+
  geom_point()+
  geom_hline(yintercept = 0,color="blue")+
  geom_hline(yintercept = c(-2,2),color="red",linetype="dashed")+
  labs(title="Plot Predichos vs Residuos Estandarizados",
       y="Residuos estandarizados",
       x="Predichos")

```

Se observa que efectivamente la varianza es constante dentro del intervalo pero con existencia de datos atípicos, ya que existen datos afuera del rango de ($-2,2$)

## Gráfico de predichos vs residuales estudentizados

```{r pred_res_student}
bd_pred$res_student=rstudent(mod_lin)
ggplot(bd_pred,aes(x=fit,res_student))+
  geom_point()+
  geom_hline(yintercept = 0,color="blue")+
  geom_hline(yintercept = c(-2,2),color="red",linetype="dashed")+
  labs(title="Plot Predichos vs Residuos Studentizados",
       y="Residuos Studentizados",
       x="Predichos")
```

De la misma manera que los residuos estandarizados existe varianza constante con datos atípicos.

## Valores atípicos

### variable independiente y residuos

```{r atipicos_var_indep_res_estand}
ggplot(bd_pred,aes(tasa_analfab,res_estand))+
  geom_point()+
  geom_hline(yintercept = 0,color="blue")+
    geom_hline(yintercept = c(-2,2),color="red",linetype="dashed")+
  labs(title="Plot Tasa de Analfabetismo vs Residuos",
       y="Residuos estandarizados",
       x="Tasa analfabetismo")
```

Muestra si la varianza de los errores es constante con respecto a la variable predictora en este caso tasa de analfabetismo y también para detectar datos atípicos que en este caso si existen.

# Gráfico de autocorrelación de residuos

```{r autcorrelacion_res}
ggplot(bd_pred,aes(x=c(1:length(bd$pais)),y=residuos))+
  geom_point()+
  geom_line(color="blue")+
  geom_hline(yintercept = 0)+
  labs(title="Autocorrelación de Residuos",
       y="Residuos",
       x="Números ordenados")
```

Se utiliza para detectar si existe dependencia de los datos en el tiempo si se diera una tendencia periodica se dice que los datos tienen autocorrelación, para los datos no es el caso.

# Conclusiones

* Para los datos tasa de analfabetismo y esperanza de vida se demostro que son variables correlacionadas a nivel mundial, que muestra que un país mientras menos tasa de analfabetismo tenga la esperanza de vida es más alta.

* Se estableció un modelo de regresión lineal simple el cual mostró un alto grado de ajuste y estimadores consistentes para la estimación de países que no cuenten con indicadores actualizados de tasa de analfabetismo.

* El modelo de regresión lineal planteado con las dos variables también cumple los supuestos de normalidad en el análisis de los residuos lo cual valida el modelo.

* Se recomienda indagar sobre los valores atípicos mostrados debido a que pueden ser casos muy especiales a tratar y de sacarlos arbitrariamente como afectaría al modelo.

* Se recomienda implementar covariables para poder tener una bondad de ajuste mayor que incrementará la estimación de los predicciones.


















